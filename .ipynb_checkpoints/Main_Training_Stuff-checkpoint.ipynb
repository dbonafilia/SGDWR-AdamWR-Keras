{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/dbonafilia/SGDWR-AdamWR-Keras/blob/master/Main_Training_Stuff.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KaTdYzzy2E2K"
   },
   "outputs": [],
   "source": [
    "LR = 1e-4\n",
    "EPOCHS = 1000\n",
    "EPOCHS_PER_UPDATE = 1\n",
    "RUNNAME = \"TESTING_1e4_flood_3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home\n"
     ]
    }
   ],
   "source": [
    "cd /home"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0rKXiKodtzk_"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "import torchvision.transforms.functional as F\n",
    "import random\n",
    "\n",
    "class InMemoryDataset(torch.utils.data.Dataset):\n",
    "  \n",
    "  def __init__(self, data_list, preprocess_func):\n",
    "    self.data_list = data_list\n",
    "    self.preprocess_func = preprocess_func\n",
    "  \n",
    "  def __getitem__(self, i):\n",
    "    return self.preprocess_func(self.data_list[i])\n",
    "  \n",
    "  def __len__(self):\n",
    "    return len(self.data_list)\n",
    "\n",
    "\n",
    "def processAndAugment(data):\n",
    "  (x,y) = data\n",
    "  im,label = x.copy(), y.copy()\n",
    "\n",
    "  # convert to PIL for easier transforms\n",
    "  im1 = Image.fromarray(im[0])\n",
    "  im2 = Image.fromarray(im[1])\n",
    "  label = Image.fromarray(label.squeeze())\n",
    "\n",
    "  # Get params for random transforms\n",
    "  i, j, h, w = transforms.RandomCrop.get_params(im1, (256, 256))\n",
    "  \n",
    "  im1 = F.crop(im1, i, j, h, w)\n",
    "  im2 = F.crop(im2, i, j, h, w)\n",
    "  label = F.crop(label, i, j, h, w)\n",
    "  if random.random() > 0.5:\n",
    "    im1 = F.hflip(im1)\n",
    "    im2 = F.hflip(im2)\n",
    "    label = F.hflip(label)\n",
    "  if random.random() > 0.5:\n",
    "    im1 = F.vflip(im1)\n",
    "    im2 = F.vflip(im2)\n",
    "    label = F.vflip(label)\n",
    "  \n",
    "  norm = transforms.Normalize([0.6851, 0.5235], [0.0820, 0.1102])\n",
    "  im = torch.stack([transforms.ToTensor()(im1).squeeze(), transforms.ToTensor()(im2).squeeze()])\n",
    "  im = norm(im)\n",
    "  label = transforms.ToTensor()(label).squeeze()\n",
    "  if torch.sum(label.gt(.003) * label.lt(.004)):\n",
    "    label *= 255\n",
    "  label = label.round()\n",
    "\n",
    "  return im, label\n",
    "\n",
    "\n",
    "def processTestIm(data):\n",
    "  (x,y) = data\n",
    "  im,label = x.copy(), y.copy()\n",
    "  norm = transforms.Normalize([0.6851, 0.5235], [0.0820, 0.1102])\n",
    "  #label[0][0][0] = 255\n",
    "  # convert to PIL for easier transforms\n",
    "  im_c1 = Image.fromarray(im[0]).resize((512,512))\n",
    "  im_c2 = Image.fromarray(im[1]).resize((512,512))\n",
    "  label = Image.fromarray(label.squeeze()).resize((512,512))\n",
    "\n",
    "  im_c1s = [F.crop(im_c1, 0, 0, 256, 256), F.crop(im_c1, 0, 256, 256, 256),\n",
    "            F.crop(im_c1, 256, 0, 256, 256), F.crop(im_c1, 256, 256, 256, 256)]\n",
    "  im_c2s = [F.crop(im_c2, 0, 0, 256, 256), F.crop(im_c2, 0, 256, 256, 256),\n",
    "            F.crop(im_c2, 256, 0, 256, 256), F.crop(im_c2, 256, 256, 256, 256)]\n",
    "  labels = [F.crop(label, 0, 0, 256, 256), F.crop(label, 0, 256, 256, 256),\n",
    "            F.crop(label, 256, 0, 256, 256), F.crop(label, 256, 256, 256, 256)]\n",
    "\n",
    "\n",
    "  ims = [torch.stack((transforms.ToTensor()(x).squeeze(),\n",
    "                    transforms.ToTensor()(y).squeeze()))\n",
    "                    for (x,y) in zip(im_c1s, im_c2s)]\n",
    "  ims = [norm(im) for im in ims]\n",
    "  ims = torch.stack(ims)\n",
    "  labels = [(transforms.ToTensor()(label).squeeze()) for label in labels]\n",
    "  labels = torch.stack(labels)\n",
    "  if torch.sum(labels.gt(.003) * labels.lt(.004)):\n",
    "    labels *= 255\n",
    "  labels = labels.round()\n",
    "  return ims, labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ImyxBVt52HnH"
   },
   "source": [
    "Read in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 190
    },
    "colab_type": "code",
    "id": "AcdNIUJyw11-",
    "outputId": "8cd3000e-33f8-49e2-b470-58362c763e0f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rasterio in /opt/conda/lib/python3.7/site-packages (1.1.3)\n",
      "Requirement already satisfied: snuggs>=1.4.1 in /opt/conda/lib/python3.7/site-packages (from rasterio) (1.4.7)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from rasterio) (1.18.1)\n",
      "Requirement already satisfied: click-plugins in /opt/conda/lib/python3.7/site-packages (from rasterio) (1.1.1)\n",
      "Requirement already satisfied: affine in /opt/conda/lib/python3.7/site-packages (from rasterio) (2.3.0)\n",
      "Requirement already satisfied: click<8,>=4.0 in /opt/conda/lib/python3.7/site-packages (from rasterio) (7.0)\n",
      "Requirement already satisfied: cligj>=0.5 in /opt/conda/lib/python3.7/site-packages (from rasterio) (0.5.0)\n",
      "Requirement already satisfied: attrs in /opt/conda/lib/python3.7/site-packages (from rasterio) (19.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.1.6 in /opt/conda/lib/python3.7/site-packages (from snuggs>=1.4.1->rasterio) (2.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install rasterio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eQqagN7vu7jx"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "from PIL import Image\n",
    "import rasterio\n",
    "import numpy as np\n",
    "import os\n",
    "BASEDIR = ''\n",
    "\n",
    "def getArr(fname):\n",
    "  return rasterio.open(BASEDIR + fname).read()\n",
    "\n",
    "\n",
    "def download_perm_water_data_from_file(fname):\n",
    "  with open(fname) as f:\n",
    "    data_fnames = [tuple(line) for line in csv.reader(f)]\n",
    "  i = 0\n",
    "  data = []\n",
    "  for (x,y) in data_fnames:\n",
    "    arr_x, arr_y = getArr(x), getArr(y)\n",
    "    if np.sum((arr_x != arr_x)) == 0:\n",
    "      ignore = (arr_y == -1)\n",
    "      ignore = ((np.uint8(ignore) * -1) * 256) + 1\n",
    "      arr_y *= ignore\n",
    "      data.append((arr_x, arr_y))\n",
    "      i+=1\n",
    "      print(i)\n",
    "    else:\n",
    "      print(\"skipping nan\")\n",
    "  return data\n",
    "\n",
    "def download_perm_train_data():\n",
    "  TRAINING_DATA_FILE = BASEDIR + 'permanent_water_train_data.csv'\n",
    "  return download_perm_water_data_from_file(TRAINING_DATA_FILE)\n",
    "\n",
    "def download_perm_valid_data():\n",
    "  VALID_DATA_FILE = BASEDIR + 'permanent_water_validation_data.csv'\n",
    "  return download_perm_water_data_from_file(VALID_DATA_FILE)\n",
    "\n",
    "def download_perm_test_data():\n",
    "  TEST_DATA_FILE = BASEDIR + 'permanent_water_test_data.csv'\n",
    "  return download_perm_water_data_from_file(TEST_DATA_FILE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!sudo mkdir files3/S1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!gsutil -m rsync gs://cnn_chips/S1 files3/S1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!gsutil -m rsync gs://cnn_chips/NoQC files3/NoQC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 422
    },
    "colab_type": "code",
    "id": "j3MLJOeivXBG",
    "outputId": "54903c68-a576-4edc-ad6c-21623e327429"
   },
   "outputs": [],
   "source": [
    "#!echo \"deb http://packages.cloud.google.com/apt gcsfuse-bionic main\" > /etc/apt/sources.list.d/gcsfuse.list\n",
    "#!curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -\n",
    "#!apt -qq update\n",
    "#!apt -qq install gcsfuse\n",
    "\n",
    "#!sudo mkdir files4\n",
    "#!gcsfuse --implicit-dirs cnn_chips files4\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZjFk6FlhHAR4"
   },
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "def getArrFlood(fname):\n",
    "  return rasterio.open(fname).read()\n",
    "\n",
    "def download_flood_water_data_from_list(l):\n",
    "  print(\"WHYYYYY\")\n",
    "  i= 0\n",
    "  tot_nan = 0\n",
    "  tot_good = 0\n",
    "  flood_data = []\n",
    "  for (im_fname, mask_fname) in l:\n",
    "    if not os.path.exists(os.path.join(\"files3/\", im_fname)):\n",
    "      continue\n",
    "    arr_x = np.nan_to_num(getArrFlood(os.path.join(\"files3/\", im_fname)))\n",
    "    arr_y = getArrFlood(os.path.join(\"files3/\", mask_fname))\n",
    "    ignore = (arr_y == -1)\n",
    "    ignore = ((np.uint8(ignore) * -1) * 256) + 1\n",
    "    arr_y *= ignore\n",
    "    arr_y = np.uint8(getArrFlood(os.path.join(\"files3/\", mask_fname)))\n",
    "    if np.sum((arr_y != arr_y)) == 0:\n",
    "      arr_x = np.clip(arr_x, -50, 1)\n",
    "      arr_x = (arr_x + 50) / 51\n",
    "      if i % 100 == 0:\n",
    "        print(i)\n",
    "        print(im_fname, mask_fname)\n",
    "      i += 1\n",
    "      flood_data.append((arr_x,arr_y))\n",
    "    else:\n",
    "      print(\"skipping nan\")\n",
    "  print(i)\n",
    "  return flood_data\n",
    "\n",
    "\n",
    "def load_flood_train_data():\n",
    "  basedir = \"files4/\"\n",
    "  fname = \"files4/flood_train_data.csv\"\n",
    "  with open(fname) as f:\n",
    "    fname = [tuple(line) for line in csv.reader(f)]\n",
    "  return download_flood_water_data_from_list(fname)\n",
    "\n",
    "def load_weak_flood_train_data():\n",
    "  basedir = \"files4/\"\n",
    "  print(\"what the fu\")\n",
    "  files = [(os.path.join(\"S1_NoQC\", x[1]), os.path.join(\"NoQC\", x[0])) for x in zip(sorted(os.listdir(\"files3/NoQC\")), sorted(os.listdir(\"files3/S1_NoQC\")))]\n",
    "  files = [x for x in files if \"Bolivia\" not in x[0]]\n",
    "  print(files[0:10])\n",
    "  return download_flood_water_data_from_list(files)\n",
    "\n",
    "def load_flood_valid_data():\n",
    "  basedir = \"files4/\"\n",
    "  fname = \"files4/flood_valid_data.csv\"\n",
    "  with open(fname) as f:\n",
    "    fname = [tuple(line) for line in csv.reader(f)]\n",
    "  return download_flood_water_data_from_list(fname)\n",
    "\n",
    "def load_flood_test_data():\n",
    "  basedir = \"files4/\"\n",
    "  fname = \"files4/flood_test_data.csv\"\n",
    "  with open(fname) as f:\n",
    "    fname = [tuple(line) for line in csv.reader(f)]\n",
    "  return download_flood_water_data_from_list(fname)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "9HN-ar8v9Wfo",
    "outputId": "93993cb0-f4e6-4ff1-9c66-9cd50d77c8a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home\n"
     ]
    }
   ],
   "source": [
    "cd ../../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "8kCCtfs7ULx_",
    "outputId": "4c5f0e83-27b2-4fd1-c11a-326fd238197a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what the fu\n",
      "[('S1_NoQC/Colombia_1031391_S1.tif', 'NoQC/Colombia_1031391_NoQC.tif'), ('S1_NoQC/Colombia_1066537_S1.tif', 'NoQC/Colombia_1066537_NoQC.tif'), ('S1_NoQC/Colombia_1100403_S1.tif', 'NoQC/Colombia_1100403_NoQC.tif'), ('S1_NoQC/Colombia_1112738_S1.tif', 'NoQC/Colombia_1112738_NoQC.tif'), ('S1_NoQC/Colombia_1115783_S1.tif', 'NoQC/Colombia_1115783_NoQC.tif'), ('S1_NoQC/Colombia_1118446_S1.tif', 'NoQC/Colombia_1118446_NoQC.tif'), ('S1_NoQC/Colombia_1131006_S1.tif', 'NoQC/Colombia_1131006_NoQC.tif'), ('S1_NoQC/Colombia_1150362_S1.tif', 'NoQC/Colombia_1150362_NoQC.tif'), ('S1_NoQC/Colombia_1175789_S1.tif', 'NoQC/Colombia_1175789_NoQC.tif'), ('S1_NoQC/Colombia_1178681_S1.tif', 'NoQC/Colombia_1178681_NoQC.tif')]\n",
      "WHYYYYY\n",
      "0\n",
      "S1_NoQC/Colombia_1031391_S1.tif NoQC/Colombia_1031391_NoQC.tif\n",
      "100\n",
      "S1_NoQC/Colombia_264490_S1.tif NoQC/Colombia_264490_NoQC.tif\n",
      "200\n",
      "S1_NoQC/Colombia_4436728_S1.tif NoQC/Colombia_4436728_NoQC.tif\n",
      "300\n",
      "S1_NoQC/Colombia_6145709_S1.tif NoQC/Colombia_6145709_NoQC.tif\n",
      "400\n",
      "S1_NoQC/Colombia_7838750_S1.tif NoQC/Colombia_7838750_NoQC.tif\n",
      "500\n",
      "S1_NoQC/Colombia_9342885_S1.tif NoQC/Colombia_9342885_NoQC.tif\n",
      "600\n",
      "S1_NoQC/Ghana_3646169_S1.tif NoQC/Ghana_3646169_NoQC.tif\n",
      "700\n",
      "S1_NoQC/Ghana_9044906_S1.tif NoQC/Ghana_9044906_NoQC.tif\n",
      "800\n",
      "S1_NoQC/India_2774101_S1.tif NoQC/India_2774101_NoQC.tif\n",
      "900\n",
      "S1_NoQC/India_4735400_S1.tif NoQC/India_4735400_NoQC.tif\n",
      "1000\n",
      "S1_NoQC/India_6646816_S1.tif NoQC/India_6646816_NoQC.tif\n",
      "1100\n",
      "S1_NoQC/India_8390255_S1.tif NoQC/India_8390255_NoQC.tif\n",
      "1200\n",
      "S1_NoQC/Mekong_1100220_S1.tif NoQC/Mekong_1100220_NoQC.tif\n",
      "1300\n",
      "S1_NoQC/Mekong_1808547_S1.tif NoQC/Mekong_1808547_NoQC.tif\n",
      "1400\n",
      "S1_NoQC/Mekong_250064_S1.tif NoQC/Mekong_250064_NoQC.tif\n",
      "1500\n",
      "S1_NoQC/Mekong_3218845_S1.tif NoQC/Mekong_3218845_NoQC.tif\n",
      "1600\n",
      "S1_NoQC/Mekong_3757783_S1.tif NoQC/Mekong_3757783_NoQC.tif\n",
      "1700\n",
      "S1_NoQC/Mekong_4501244_S1.tif NoQC/Mekong_4501244_NoQC.tif\n",
      "1800\n",
      "S1_NoQC/Mekong_5198691_S1.tif NoQC/Mekong_5198691_NoQC.tif\n",
      "1900\n",
      "S1_NoQC/Mekong_5792745_S1.tif NoQC/Mekong_5792745_NoQC.tif\n",
      "2000\n",
      "S1_NoQC/Mekong_6420382_S1.tif NoQC/Mekong_6420382_NoQC.tif\n",
      "2100\n",
      "S1_NoQC/Mekong_7111124_S1.tif NoQC/Mekong_7111124_NoQC.tif\n",
      "2200\n",
      "S1_NoQC/Mekong_7694776_S1.tif NoQC/Mekong_7694776_NoQC.tif\n",
      "2300\n",
      "S1_NoQC/Mekong_8307611_S1.tif NoQC/Mekong_8307611_NoQC.tif\n",
      "2400\n",
      "S1_NoQC/Mekong_8995985_S1.tif NoQC/Mekong_8995985_NoQC.tif\n",
      "2500\n",
      "S1_NoQC/Mekong_9792252_S1.tif NoQC/Mekong_9792252_NoQC.tif\n",
      "2600\n",
      "S1_NoQC/Nigeria_6657550_S1.tif NoQC/Nigeria_6657550_NoQC.tif\n",
      "2700\n",
      "S1_NoQC/Pakistan_2895699_S1.tif NoQC/Pakistan_2895699_NoQC.tif\n",
      "2800\n",
      "S1_NoQC/Pakistan_6658443_S1.tif NoQC/Pakistan_6658443_NoQC.tif\n",
      "2900\n",
      "S1_NoQC/Paraguay_1181475_S1.tif NoQC/Paraguay_1181475_NoQC.tif\n",
      "3000\n",
      "S1_NoQC/Paraguay_4059946_S1.tif NoQC/Paraguay_4059946_NoQC.tif\n",
      "3100\n",
      "S1_NoQC/Paraguay_6979890_S1.tif NoQC/Paraguay_6979890_NoQC.tif\n",
      "3200\n",
      "S1_NoQC/Paraguay_9704722_S1.tif NoQC/Paraguay_9704722_NoQC.tif\n",
      "3300\n",
      "S1_NoQC/Somalia_6828307_S1.tif NoQC/Somalia_6828307_NoQC.tif\n",
      "3400\n",
      "S1_NoQC/Spain_4354065_S1.tif NoQC/Spain_4354065_NoQC.tif\n",
      "3500\n",
      "S1_NoQC/Sri-Lanka_1914258_S1.tif NoQC/Sri-Lanka_1914258_NoQC.tif\n",
      "3600\n",
      "S1_NoQC/Sri-Lanka_6884382_S1.tif NoQC/Sri-Lanka_6884382_NoQC.tif\n",
      "3700\n",
      "S1_NoQC/USA_1407262_S1.tif NoQC/USA_1407262_NoQC.tif\n",
      "3800\n",
      "S1_NoQC/USA_3446397_S1.tif NoQC/USA_3446397_NoQC.tif\n",
      "3900\n",
      "S1_NoQC/USA_5413558_S1.tif NoQC/USA_5413558_NoQC.tif\n",
      "4000\n",
      "S1_NoQC/USA_7100541_S1.tif NoQC/USA_7100541_NoQC.tif\n",
      "4100\n",
      "S1_NoQC/USA_8706264_S1.tif NoQC/USA_8706264_NoQC.tif\n",
      "4160\n"
     ]
    }
   ],
   "source": [
    "train_data = load_weak_flood_train_data() #download_perm_train_data()\n",
    "train_dataset = InMemoryDataset(train_data, processAndAugment)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=16, shuffle=True, sampler=None,\n",
    "                  batch_sampler=None, num_workers=0, collate_fn=None,\n",
    "                  pin_memory=True, drop_last=False, timeout=0,\n",
    "                  worker_init_fn=None)\n",
    "train_iter = iter(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.26 KiB    gs://cnn_chips/NoQC/Bolivia_1041766_NoQC.tif\n"
     ]
    }
   ],
   "source": [
    "!gsutil du -h -s gs://cnn_chips/NoQC/Bolivia_1041766_NoQC.tif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil du -h -s gs://cnn_chips/QC/Ghana_103272_QC.tif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil du -h -s gs://cnn_chips/S1/Ghana_103272_S1.tif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil du -h -s gs://cnn_chips/S1_NoQC/Bolivia_1041766_S1.tif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "GDa86WdzgdkH",
    "outputId": "f29debe4-669e-4955-d850-7aab77fd0834"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WHYYYYY\n",
      "0\n",
      "S1/Ghana_5079_S1.tif QC_v2/Ghana_5079_QC.tif\n",
      "89\n"
     ]
    }
   ],
   "source": [
    "valid_data = load_flood_valid_data() #download_perm_valid_data()\n",
    "valid_dataset = InMemoryDataset(valid_data, processTestIm)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=4, shuffle=True, sampler=None,\n",
    "                  batch_sampler=None, num_workers=0, collate_fn=lambda x: (torch.cat([a[0] for a in x], 0), torch.cat([a[1] for a in x], 0)),\n",
    "                  pin_memory=True, drop_last=False, timeout=0,\n",
    "                  worker_init_fn=None)\n",
    "valid_iter = iter(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "BkBTS7D684Lw",
    "outputId": "889369c0-0807-4c63-f2ba-4e8a41cc9cb8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WHYYYYY\n",
      "0\n",
      "S1/Ghana_313799_S1.tif QC_v2/Ghana_313799_QC.tif\n",
      "90\n"
     ]
    }
   ],
   "source": [
    "test_data = load_flood_test_data()\n",
    "test_dataset = InMemoryDataset(test_data, processTestIm)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=True, sampler=None,\n",
    "                  batch_sampler=None, num_workers=0, collate_fn=lambda x: x[0],\n",
    "                  pin_memory=True, drop_last=False, timeout=0,\n",
    "                  worker_init_fn=None)\n",
    "test_iter = iter(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#usa_data = load_flood_test_data()\n",
    "#usa_dataset = InMemoryDataset(usa_data, processTestIm)\n",
    "#usa_loader = torch.utils.data.DataLoader(usa_dataset, batch_size=1, shuffle=True, sampler=None,\n",
    "#                  batch_sampler=None, num_workers=0, collate_fn=lambda x: x[0],\n",
    "#                  pin_memory=True, drop_last=False, timeout=0,\n",
    "#                  worker_init_fn=None)\n",
    "#usa_iter = iter(usa_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1MqJiLAx6_Pc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q00osps22aUU"
   },
   "source": [
    "Set up net/parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "DF4k-jQM2gCP",
    "outputId": "1c189728-d219-4107-926b-523962735635"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FCN(\n",
       "  (backbone): IntermediateLayerGetter(\n",
       "    (conv1): Conv2d(2, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): GroupNorm(16, 64, eps=1e-05, affine=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): GroupNorm(16, 64, eps=1e-05, affine=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): GroupNorm(16, 64, eps=1e-05, affine=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): GroupNorm(16, 256, eps=1e-05, affine=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): GroupNorm(16, 256, eps=1e-05, affine=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): GroupNorm(16, 64, eps=1e-05, affine=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): GroupNorm(16, 64, eps=1e-05, affine=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): GroupNorm(16, 256, eps=1e-05, affine=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): GroupNorm(16, 64, eps=1e-05, affine=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): GroupNorm(16, 64, eps=1e-05, affine=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): GroupNorm(16, 256, eps=1e-05, affine=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): GroupNorm(16, 128, eps=1e-05, affine=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): GroupNorm(16, 128, eps=1e-05, affine=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): GroupNorm(16, 512, eps=1e-05, affine=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): GroupNorm(16, 512, eps=1e-05, affine=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): GroupNorm(16, 128, eps=1e-05, affine=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): GroupNorm(16, 128, eps=1e-05, affine=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): GroupNorm(16, 512, eps=1e-05, affine=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): GroupNorm(16, 128, eps=1e-05, affine=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): GroupNorm(16, 128, eps=1e-05, affine=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): GroupNorm(16, 512, eps=1e-05, affine=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): GroupNorm(16, 128, eps=1e-05, affine=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): GroupNorm(16, 128, eps=1e-05, affine=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): GroupNorm(16, 512, eps=1e-05, affine=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): GroupNorm(16, 256, eps=1e-05, affine=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): GroupNorm(16, 256, eps=1e-05, affine=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): GroupNorm(16, 1024, eps=1e-05, affine=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): GroupNorm(16, 1024, eps=1e-05, affine=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): GroupNorm(16, 256, eps=1e-05, affine=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): GroupNorm(16, 256, eps=1e-05, affine=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): GroupNorm(16, 1024, eps=1e-05, affine=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): GroupNorm(16, 256, eps=1e-05, affine=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): GroupNorm(16, 256, eps=1e-05, affine=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): GroupNorm(16, 1024, eps=1e-05, affine=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): GroupNorm(16, 256, eps=1e-05, affine=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): GroupNorm(16, 256, eps=1e-05, affine=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): GroupNorm(16, 1024, eps=1e-05, affine=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): GroupNorm(16, 256, eps=1e-05, affine=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): GroupNorm(16, 256, eps=1e-05, affine=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): GroupNorm(16, 1024, eps=1e-05, affine=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): GroupNorm(16, 256, eps=1e-05, affine=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): GroupNorm(16, 256, eps=1e-05, affine=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): GroupNorm(16, 1024, eps=1e-05, affine=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): GroupNorm(16, 512, eps=1e-05, affine=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): GroupNorm(16, 512, eps=1e-05, affine=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): GroupNorm(16, 2048, eps=1e-05, affine=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): GroupNorm(16, 2048, eps=1e-05, affine=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): GroupNorm(16, 512, eps=1e-05, affine=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "        (bn2): GroupNorm(16, 512, eps=1e-05, affine=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): GroupNorm(16, 2048, eps=1e-05, affine=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): GroupNorm(16, 512, eps=1e-05, affine=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "        (bn2): GroupNorm(16, 512, eps=1e-05, affine=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): GroupNorm(16, 2048, eps=1e-05, affine=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): FCNHead(\n",
       "    (0): Conv2d(2048, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (1): GroupNorm(16, 512, eps=1e-05, affine=True)\n",
       "    (2): ReLU()\n",
       "    (3): Dropout(p=0.1, inplace=False)\n",
       "    (4): Conv2d(512, 2, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "\n",
    "net = models.segmentation.fcn_resnet50(pretrained=False, num_classes=2, pretrained_backbone=False)\n",
    "net.backbone.conv1 = nn.Conv2d(2, 64, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "criterion = nn.CrossEntropyLoss(weight=torch.tensor([1,8]).float().cuda(), ignore_index=255) # \n",
    "#criterion = nn.CrossEntropyLoss(ignore_index=255)\n",
    "optimizer = torch.optim.AdamW(net.parameters(),lr=LR)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 260, T_mult=2, eta_min=0, last_epoch=-1)\n",
    "def convertBNtoGN(module, num_groups=16):\n",
    "  if isinstance(module, torch.nn.modules.batchnorm.BatchNorm2d):\n",
    "    return nn.GroupNorm(num_groups, module.num_features,\n",
    "                        eps=module.eps, affine=module.affine)\n",
    "    if module.affine:\n",
    "        mod.weight.data = module.weight.data.clone().detach()\n",
    "        mod.bias.data = module.bias.data.clone().detach()\n",
    "\n",
    "  for name, child in module.named_children():\n",
    "      module.add_module(name, convertBNtoGN(child, num_groups=num_groups))\n",
    "\n",
    "  return module\n",
    "\n",
    "net = convertBNtoGN(net)\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "AEyYBOyQdU0L",
    "outputId": "84b1eb15-00cc-4d6f-b273-d4f592e1c383"
   },
   "outputs": [],
   "source": [
    "#torch.load(\"/content/gdrive/My Drive/TESTING_1e4_flood_3_97_0.4078918397426605.cp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2jwEvqA885dz"
   },
   "source": [
    "Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WMd65d3784oH"
   },
   "outputs": [],
   "source": [
    "def computeIOU(output, target):\n",
    "  output = torch.argmax(output, dim=1).flatten() \n",
    "  target = target.flatten()\n",
    "  no_ignore = target.ne(255).cuda()\n",
    "  output = output.masked_select(no_ignore)\n",
    "  target = target.masked_select(no_ignore)\n",
    "  intersection = torch.sum(output * target)\n",
    "  union = torch.sum(target) + torch.sum(output) - intersection\n",
    "  return (intersection + .0000001) / (union + .0000001)\n",
    "  \n",
    "\n",
    "def computeAccuracy(output, target):\n",
    "  output = torch.argmax(output, dim=1).flatten() \n",
    "  target = target.flatten()\n",
    "  no_ignore = target.ne(255).cuda()\n",
    "  output = output.masked_select(no_ignore)\n",
    "  target = target.masked_select(no_ignore)\n",
    "  correct = torch.sum(output.eq(target))\n",
    "  return correct.float() / len(target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "jiP-eu3NLxIA",
    "outputId": "73ba33de-d99b-4957-f0e7-ee4f6beb172a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(7.6294e-13, device='cuda:0')\n",
      "tensor(1., device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "test_1 = torch.ones(2, 2, 256, 256)\n",
    "test_2 = torch.zeros(2, 256, 256)\n",
    "test_3 = torch.ones(2, 256, 256)\n",
    "\n",
    "\n",
    "print(computeIOU(test_1.cuda(), test_2.cuda()))\n",
    "print(computeIOU(test_1.cuda(), test_3.cuda()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XBHHATa-2h3A"
   },
   "source": [
    "Train/Validation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pg1PiQ192g3g"
   },
   "outputs": [],
   "source": [
    "\n",
    "training_losses = []\n",
    "training_accuracies = []\n",
    "training_ious = []\n",
    "valid_losses = []\n",
    "valid_accuracies = []\n",
    "valid_ious = []\n",
    "\n",
    "def train(inputs, labels, net, optimizer, scheduler):\n",
    "  global running_loss\n",
    "  global running_iou\n",
    "  global running_count\n",
    "  global running_accuracy\n",
    "  # zero the parameter gradients\n",
    "  optimizer.zero_grad()\n",
    "  net = net.cuda()\n",
    "  # forward + backward + optimize\n",
    "  outputs = net(inputs.cuda())\n",
    "  loss = criterion(outputs[\"out\"], labels.long().cuda())\n",
    "  loss.backward()\n",
    "  optimizer.step()\n",
    "  scheduler.step()\n",
    "\n",
    "  running_loss += loss\n",
    "  running_iou += computeIOU(outputs[\"out\"], labels.cuda())\n",
    "  running_accuracy += computeAccuracy(outputs[\"out\"], labels.cuda())\n",
    "  running_count += 1\n",
    "\n",
    "def validation_loop(validation_data_loader, net):\n",
    "  global running_loss\n",
    "  global running_iou\n",
    "  global running_count\n",
    "  global running_accuracy\n",
    "  global max_valid_iou\n",
    "\n",
    "  global training_losses\n",
    "  global training_accuracies\n",
    "  global training_ious\n",
    "  global valid_losses\n",
    "  global valid_accuracies\n",
    "  global valid_ious\n",
    "\n",
    "  net = net.eval()\n",
    "  net = net.cuda()\n",
    "  count = 0\n",
    "  iou = 0\n",
    "  loss = 0\n",
    "  accuracy = 0\n",
    "  with torch.no_grad():\n",
    "      for (images, labels) in validation_data_loader:\n",
    "          net = net.cuda()\n",
    "          outputs = net(images.cuda())\n",
    "          valid_loss = criterion(outputs[\"out\"], labels.long().cuda())\n",
    "          valid_iou = computeIOU(outputs[\"out\"], labels.cuda())\n",
    "          valid_accuracy = computeAccuracy(outputs[\"out\"], labels.cuda())\n",
    "          iou += valid_iou\n",
    "          loss += valid_loss\n",
    "          accuracy += valid_accuracy\n",
    "          count += 1\n",
    "\n",
    "  iou = iou / count\n",
    "  accuracy = accuracy / count\n",
    "\n",
    "  if iou > max_valid_iou:\n",
    "    max_valid_iou = iou\n",
    "    save_path = os.path.join(BASEDIR, \"{}_{}_{}.cp\".format(RUNNAME, i, iou.item()))\n",
    "    #torch.save(net.state_dict(), save_path)\n",
    "    print(\"model saved at\", save_path)\n",
    "\n",
    "  loss = loss / count\n",
    "  print(\"Training Loss:\", running_loss / running_count)\n",
    "  print(\"Training IOU:\", running_iou / running_count)\n",
    "  print(\"Training Accuracy:\", running_accuracy / running_count)\n",
    "  print(\"Validation Loss:\", loss)\n",
    "  print(\"Validation IOU:\", iou)\n",
    "  print(\"Validation Accuracy:\", accuracy)\n",
    "\n",
    "\n",
    "  training_losses.append(running_loss / running_count)\n",
    "  training_accuracies.append(running_accuracy / running_count)\n",
    "  training_ious.append(running_iou / running_count)\n",
    "  valid_losses.append(loss)\n",
    "  valid_accuracies.append(accuracy)\n",
    "  valid_ious.append(iou)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_loop(test_data_loader, net):\n",
    "  net = net.eval()\n",
    "  net = net.cuda()\n",
    "  count = 0\n",
    "  iou = 0\n",
    "  loss = 0\n",
    "  accuracy = 0\n",
    "  with torch.no_grad():\n",
    "      for (images, labels) in tqdm(test_data_loader):\n",
    "          net = net.cuda()\n",
    "          outputs = net(images.cuda())\n",
    "          valid_loss = criterion(outputs[\"out\"], labels.long().cuda())\n",
    "          valid_iou = computeIOU(outputs[\"out\"], labels.cuda())\n",
    "          iou += valid_iou\n",
    "          accuracy += computeAccuracy(outputs[\"out\"], labels.cuda())\n",
    "          count += 1\n",
    "\n",
    "  iou = iou / count\n",
    "  print(\"Test IOU:\", iou)\n",
    "  print(\"Test Accuracy:\", accuracy / count)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4nU8Rxpa2l3p"
   },
   "source": [
    "Train Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y0h841wY2npi"
   },
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "from IPython.display import clear_output\n",
    "\n",
    "running_loss = 0\n",
    "running_iou = 0\n",
    "running_count = 0\n",
    "running_accuracy = 0\n",
    "\n",
    "training_losses = []\n",
    "training_accuracies = []\n",
    "training_ious = []\n",
    "valid_losses = []\n",
    "valid_accuracies = []\n",
    "valid_ious = []\n",
    "\n",
    "\n",
    "def train_epoch(net, optimizer, scheduler, train_iter):\n",
    "  for (inputs, labels) in tqdm(train_iter):\n",
    "    train(inputs.cuda(), labels.cuda(), net.cuda(), optimizer, scheduler)\n",
    " \n",
    "\n",
    "def train_validation_loop(net, optimizer, scheduler, train_loader,\n",
    "                          valid_loader, num_epochs, cur_epoch):\n",
    "  global running_loss\n",
    "  global running_iou\n",
    "  global running_count\n",
    "  global running_accuracy\n",
    "  net = net.train()\n",
    "  running_loss = 0\n",
    "  running_iou = 0\n",
    "  running_count = 0\n",
    "  running_accuracy = 0\n",
    "  for i in tqdm(range(num_epochs)):\n",
    "    train_iter = iter(train_loader)\n",
    "    train_epoch(net, optimizer, scheduler, train_iter)\n",
    "  clear_output()\n",
    "  print(\"Current Epoch:\", cur_epoch)\n",
    "  validation_loop(iter(valid_loader), net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xPSjS-pf2vHD"
   },
   "source": [
    "test_loader[0] == usa_loader[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 482,
     "referenced_widgets": [
      "ed787105fcaa4c3c812a76c4c603d5f5",
      "25fb338b9ebb4053ac0218c253389a46",
      "0a5bf508b6b44bee8ce55182e0af6fec",
      "51b4002a832f4754b087443f75d3c97f",
      "8a35991cccc84d0494384ac2c018727c",
      "f93cc6f609e94593a6b7133ae868285e",
      "b9ec39f9a47248928f102018e2e0f116",
      "ccd281b6c8104e4fa01533165fbb2ea0",
      "8c714337e16c446281218656cb330d37",
      "82300de7ef9c4460886669b056253500",
      "44ca7d253a0c46b3b704fe67a70c52eb",
      "cca70317fa824574aa562d981391c46f",
      "ca76bbb74d4d45bc8a7ac4e1b5466e1b",
      "84eab0bbbc3d46e89df8e66cc3134be4",
      "e5e4e39f80ff4ff4b1e2e723d71e64fa",
      "c071047b9b5b420dbb5233397841a7b5"
     ]
    },
    "colab_type": "code",
    "id": "ugcVXfKj1kg8",
    "outputId": "0cc7ebd8-a627-485b-c951-04398eff0fc2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Epoch: 7\n",
      "model saved at TESTING_1e4_flood_3_7_0.4733611047267914.cp\n",
      "Training Loss: tensor(0.3069, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Training IOU: tensor(0.4838, device='cuda:0')\n",
      "Training Accuracy: tensor(0.8666, device='cuda:0')\n",
      "Validation Loss: tensor(0.3757, device='cuda:0')\n",
      "Validation IOU: tensor(0.4734, device='cuda:0')\n",
      "Validation Accuracy: tensor(0.9090, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max valid iou: tensor(0.4734, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "760bafc734c74a1fa80f33169ed5f722",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=90.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test IOU: tensor(0.3645, device='cuda:0')\n",
      "Test Accuracy: tensor(0.9168, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "max_valid_iou = 0\n",
    "start = 0\n",
    "\n",
    "epochs = []\n",
    "training_losses = []\n",
    "training_accuracies = []\n",
    "training_ious = []\n",
    "valid_losses = []\n",
    "valid_accuracies = []\n",
    "valid_ious = []\n",
    "\n",
    "\n",
    "\n",
    "for i in range(start, 1000):\n",
    "  train_validation_loop(net, optimizer, scheduler, train_loader, valid_loader, 1, i)\n",
    "  epochs.append(i)\n",
    "  x = epochs\n",
    "  plt.plot(x, training_losses, label='training losses')\n",
    "  plt.plot(x, training_accuracies, 'tab:orange', label='training accuracy')\n",
    "  plt.plot(x, training_ious, 'tab:purple', label='training iou')\n",
    "  plt.plot(x, valid_losses, label='valid losses')\n",
    "  plt.plot(x, valid_accuracies, 'tab:red',label='valid accuracy')\n",
    "  plt.plot(x, valid_ious, 'tab:green',label='valid iou')\n",
    "  plt.legend(loc=\"upper left\")\n",
    "\n",
    "  display(plt.show())\n",
    "\n",
    "  print(\"max valid iou:\", max_valid_iou)\n",
    "  test_loop(test_loader, net)\n",
    "  if max_valid_iou > .45:\n",
    "    break\n",
    "  #test_loop(usa_loader, net)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LArLAmjuOHB6"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa73869f5fa44b66a5baa7dae29388af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=23.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.42280263"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from skimage.filters import threshold_otsu\n",
    "water_probs = []\n",
    "net = net.eval()\n",
    "net = net.cuda()\n",
    "with torch.no_grad():\n",
    "  for (images, labels) in tqdm(valid_loader):\n",
    "      net = net.cuda()\n",
    "      net_out = net(images.cuda())[\"out\"]\n",
    "      water_prob = torch.nn.Softmax2d()(net_out)[:,1,:,:]\n",
    "      water_probs.append(water_prob)\n",
    "\n",
    "        \n",
    "threshold_otsu(torch.cat(water_probs).detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fBGqX5QidWAR"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5f7353790ce43d2a1d840076a712f2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=23.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 64.00 MiB (GPU 0; 15.75 GiB total capacity; 14.62 GiB already allocated; 42.88 MiB free; 14.72 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-30069d9163bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mnet_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"out\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mwater_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSoftmax2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mwater_probs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwater_prob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torchvision/models/segmentation/_utils.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;31m# contract: features is a dict of tensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackbone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torchvision/models/_utils.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_layers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m                 \u001b[0mout_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_layers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownsample\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/normalization.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    224\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m         return F.group_norm(\n\u001b[0;32m--> 226\u001b[0;31m             input, self.num_groups, self.weight, self.bias, self.eps)\n\u001b[0m\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mgroup_norm\u001b[0;34m(input, num_groups, weight, bias, eps)\u001b[0m\n\u001b[1;32m   1704\u001b[0m     \"\"\"\n\u001b[1;32m   1705\u001b[0m     return torch.group_norm(input, num_groups, weight, bias, eps,\n\u001b[0;32m-> 1706\u001b[0;31m                             torch.backends.cudnn.enabled)\n\u001b[0m\u001b[1;32m   1707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 64.00 MiB (GPU 0; 15.75 GiB total capacity; 14.62 GiB already allocated; 42.88 MiB free; 14.72 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6vUtM4eELiYw"
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 15.75 GiB total capacity; 14.68 GiB already allocated; 10.88 MiB free; 14.75 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-7c1750b361e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnet_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"out\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torchvision/models/segmentation/_utils.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;31m# contract: features is a dict of tensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackbone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torchvision/models/_utils.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_layers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m                 \u001b[0mout_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_layers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownsample\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/normalization.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    224\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m         return F.group_norm(\n\u001b[0;32m--> 226\u001b[0;31m             input, self.num_groups, self.weight, self.bias, self.eps)\n\u001b[0m\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mgroup_norm\u001b[0;34m(input, num_groups, weight, bias, eps)\u001b[0m\n\u001b[1;32m   1704\u001b[0m     \"\"\"\n\u001b[1;32m   1705\u001b[0m     return torch.group_norm(input, num_groups, weight, bias, eps,\n\u001b[0;32m-> 1706\u001b[0;31m                             torch.backends.cudnn.enabled)\n\u001b[0m\u001b[1;32m   1707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 15.75 GiB total capacity; 14.68 GiB already allocated; 10.88 MiB free; 14.75 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "i, l = next(iter(test_loader))\n",
    "net_out = net(i.cuda())[\"out\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "abV6emoPLsFI"
   },
   "outputs": [],
   "source": [
    "torch.nn.Softmax2d()(net_out)[:,1,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eLKMyzLHLxXT"
   },
   "outputs": [],
   "source": [
    "def computeAccuracy(output, target):\n",
    "  output = torch.argmax(output, dim=1).flatten() \n",
    "  target = target.flatten()\n",
    "  no_ignore = target.ne(255).cuda()\n",
    "  output = output.masked_select(no_ignore)\n",
    "  target = target.masked_select(no_ignore)\n",
    "  correct = torch.sum(output.eq(target))\n",
    "  return correct.float() / len(target)\n",
    "\n",
    "computeAccuracy(net_out[2].unsqueeze(0), l.cuda()[2].unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rD9WeWs2Y1vM"
   },
   "outputs": [],
   "source": [
    "for "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aFJH0pW0YgHc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9Hm2heSCL8aI"
   },
   "outputs": [],
   "source": [
    "def computeIOU(output, target):\n",
    "  output = torch.argmax(output, dim=1).flatten()\n",
    "  target = target.flatten()\n",
    "  no_ignore = target.ne(255).cuda()\n",
    "  print(output)\n",
    "  print(target)\n",
    "  output = output.masked_select(no_ignore)\n",
    "  target = target.masked_select(no_ignore)\n",
    "  print(output)\n",
    "  print(target)\n",
    "  intersection = torch.sum(output * target)\n",
    "  union = torch.sum(target) + torch.sum(output) - intersection\n",
    "  return (intersection + .0000001) / (union + .0000001)\n",
    "\n",
    "im = Image.fromarray(np.uint8(output[0].cpu().numpy() * 255) , 'L')\n",
    "computeIOU(torch.stack([net_out[3]]), torch.stack([l[3].cuda()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bpAkDF1LWXbT"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XXG7gkm3NbZ5"
   },
   "outputs": [],
   "source": [
    "print(torch.argmax(torch.stack([net_out[1]]), dim=1).flatten())\n",
    "c = torch.argmax(torch.stack([net_out[3]]), dim=1)\n",
    "a = torch.argmax(torch.stack([net_out[1]]), dim=1).flatten()\n",
    "print(a.shape)\n",
    "print(l[0].flatten().shape)\n",
    "pred_wat = a.eq(1)\n",
    "real_wat = l[1].flatten().cuda().eq(1)\n",
    "print(a.eq(1) * (l[1].flatten().cuda().eq(1)))\n",
    "inter = torch.sum(pred_wat * real_wat)\n",
    "union = torch.sum(pred_wat) + torch.sum(real_wat) - inter\n",
    "print(torch.sum(pred_wat * real_wat))\n",
    "print(torch.sum(pred_wat) + torch.sum(real_wat))\n",
    "print(torch.sum(pred_wat) + torch.sum(real_wat) / ((torch.sum(pred_wat) + torch.sum(real_wat) - torch.sum(pred_wat) + torch.sum(real_wat))))\n",
    "print(inter)\n",
    "print(union)\n",
    "iou = inter.float() / union\n",
    "print(iou)\n",
    "computeIOU(torch.stack([net_out[1]]).cuda(), torch.stack([l[1]]).cuda())\n",
    "print(c.squeeze())\n",
    "print(\"match\", torch.sum(c.squeeze().eq(1)))\n",
    "print((c.squeeze().cpu().detach().numpy() * 255))\n",
    "im = Image.fromarray((c.squeeze().cpu().detach().numpy() * 255), 'L')\n",
    "im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bbYaEoKAPrCo"
   },
   "outputs": [],
   "source": [
    "im = Image.fromarray((l[3].squeeze().cpu().detach().numpy() * 255), 'L')\n",
    "im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hqdEWkpbObjy"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.colors as colors\n",
    "#i, l = next(iter(valid_loader))\n",
    "#print(l[0])\n",
    "#i = 2\n",
    "plt.imshow(i[0][0])\n",
    "#plt.imshow(l[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6T0KFNs_eMYP"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Zk8q_ZmITL5x"
   },
   "outputs": [],
   "source": [
    "c = torch.argmax(torch.stack([net_out[2]]), dim=1)\n",
    "c = c.squeeze().cpu().detach().numpy()\n",
    "plt.imshow(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JiRb-kYyW_TV"
   },
   "outputs": [],
   "source": [
    "test_dataset[0][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cLqIdbNOxlC4"
   },
   "outputs": [],
   "source": [
    "mean = 0.\n",
    "std = 0.\n",
    "i = 0\n",
    "total_water = 0\n",
    "total_land = 0\n",
    "total_mix = 0\n",
    "for images, label in train_loader:\n",
    "    batch_samples = images.size(0) # batch size (the last batch can have smaller size!)\n",
    "    images = images.view(batch_samples, images.size(1), -1)\n",
    "    if torch.sum(images != images) != 0:\n",
    "      print(\"NAN\")\n",
    "      continue\n",
    "    #print(images)\n",
    "    #print(images.max(2))\n",
    "    #print(images.min(2))\n",
    "    #print(images.mean(2))\n",
    "    total_water += torch.sum(label == 1)\n",
    "    total_land += torch.sum(label == 0)\n",
    "    total_mix += torch.sum(label == 255)\n",
    "    #print(images)\n",
    "    mean += images.mean(2).sum(0)\n",
    "    std += images.std(2).sum(0)\n",
    "    i += len(images)\n",
    "\n",
    "mean /= i\n",
    "std /= i\n",
    "mean, std, total_water, total_land, total_water.float() / (total_land + total_water.float() + total_mix), total_land.float() / (total_land + total_water.float() + total_mix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 83,
     "referenced_widgets": [
      "52308f87ad3d46a885815de01d2a8402",
      "1c740a2079f04eb1b1c3586cf060087a",
      "fa7fbb20e21748568096c1aa226bf09d",
      "65bfba0c282c4de2a8c7c738431f617f",
      "bb6710d665f64746a816abac2cb6ad1a",
      "785c07b1622a42648b66c6ce1ddf593f",
      "67a9b7f67a274e1ca75dc8ea9c72e3b1",
      "a22b328f55be4871929c1bf872887814"
     ]
    },
    "colab_type": "code",
    "id": "jywv7vAt3ZDT",
    "outputId": "96542618-894e-4141-ccfa-8f9ede24acec"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f81280988ea4d0d99281aedbc3b4576",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=90.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test IOU: tensor(0.2750, device='cuda:0')\n",
      "Test Accuracy: tensor(0.8847, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "def test_loop(test_data_loader, net):\n",
    "  net = net.eval()\n",
    "  net = net.cuda()\n",
    "  count = 0\n",
    "  iou = 0\n",
    "  loss = 0\n",
    "  accuracy = 0\n",
    "  with torch.no_grad():\n",
    "      for (images, labels) in tqdm(test_data_loader):\n",
    "          net = net.cuda()\n",
    "          outputs = net(images.cuda())\n",
    "          valid_loss = criterion(outputs[\"out\"], labels.long().cuda())\n",
    "          valid_iou = computeIOU(outputs[\"out\"], labels.cuda())\n",
    "          iou += valid_iou\n",
    "          accuracy += computeAccuracy(outputs[\"out\"], labels.cuda())\n",
    "          count += 1\n",
    "\n",
    "  iou = iou / count\n",
    "  print(\"Test IOU:\", iou)\n",
    "  print(\"Test Accuracy:\", accuracy / count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0ISCe8PnTNEs"
   },
   "outputs": [],
   "source": [
    "i, l = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r6K1xRRQuTze"
   },
   "outputs": [],
   "source": [
    "net = net.cuda()\n",
    "outputs = net(i.cuda())[\"out\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LCbHrNLTT5E_"
   },
   "outputs": [],
   "source": [
    "#print(torch.argmax(outputs, dim=1))\n",
    "print(torch.argmax(outputs, dim=1).shape)\n",
    "print(torch.sum(torch.argmax(outputs, dim=1)[4]))\n",
    "\n",
    "plt.imshow(torch.argmax(outputs, dim=1)[4].cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vxS3FpYyVB5c"
   },
   "outputs": [],
   "source": [
    "plt.imshow(train_data[0][0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(train_data[0][1].squeeze() == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.sum(l[2] == 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lIEtnUpSUCaQ"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "import rasterio\n",
    "import numpy as np\n",
    "im = Image.fromarray(np.uint8(flood_data[4][0][1] * 255) , 'L')\n",
    "print(\"did stuff\")\n",
    "im.convert(\"L\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YUSPDxlMUTgi"
   },
   "outputs": [],
   "source": [
    "xf, yf = processTestIm(flood_data[0])\n",
    "xp, yp = valid_dataset[1]\n",
    "print(xp.unsqueeze(0).shape)\n",
    "transforms.ToPILImage()(net(xp.unsqueeze(0).cuda())[\"out\"][0].cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WOvnJf77YyPY"
   },
   "outputs": [],
   "source": [
    "xp, yp = valid_dataset[1]\n",
    "print(valid_data[0][1])\n",
    "print(Image.fromarray(valid_data[1][0][0] * 255).convert(\"L\").size)\n",
    "Image.fromarray(valid_data[1][1][0] * 255).convert(\"L\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PP08GQ0nvURS"
   },
   "outputs": [],
   "source": [
    "Image.fromarray(xp[0].cpu().numpy() * 255).convert(\"L\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I_VB1TL0s8Ea"
   },
   "outputs": [],
   "source": [
    "#print(yp)\n",
    "yp\n",
    "Image.fromarray(yp.cpu().numpy() * 255).convert(\"L\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nJMONX77uQ7g"
   },
   "outputs": [],
   "source": [
    "print(yp)\n",
    "Image.fromarray(yp.cpu().numpy() * 255).convert(\"L\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ezrBdf_sY3hw"
   },
   "outputs": [],
   "source": [
    "def processAndAugment(data):\n",
    "  (x,y) = data\n",
    "  im,label = x.copy(), y.copy()\n",
    "\n",
    "  # convert to PIL for easier transforms\n",
    "  im1 = transforms.ToPILImage()(im[0])\n",
    "  im2 = transforms.ToPILImage()(im[1])\n",
    "  label = transforms.ToPILImage()(label.squeeze())\n",
    "\n",
    "  # Get params for random transforms\n",
    "  i, j, h, w = transforms.RandomCrop.get_params(im1, (256, 256))\n",
    "  \n",
    "  im1 = F.crop(im1, i, j, h, w)\n",
    "  im2 = F.crop(im2, i, j, h, w)\n",
    "  label = F.crop(label, i, j, h, w)\n",
    "  if random.random() > 0.5:\n",
    "    im1 = F.hflip(im1)\n",
    "    im2 = F.hflip(im2)\n",
    "    label = F.hflip(label)\n",
    "  if random.random() > 0.5:\n",
    "    im1 = F.vflip(im1)\n",
    "    im2 = F.vflip(im2)\n",
    "    label = F.vflip(label)\n",
    "  \n",
    "  norm = transforms.Normalize([0.6851, 0.5235], [0.0820, 0.1102])\n",
    "  im = torch.stack([transforms.ToTensor()(im1).squeeze(), transforms.ToTensor()(im2).squeeze()])\n",
    "  return im, transforms.ToTensor()(label).squeeze()\n",
    "\n",
    "\n",
    "def processTestImspec(data):\n",
    "  (x,y) = data\n",
    "  im,label = x.copy(), y.copy()\n",
    "  norm = transforms.Normalize([0.6851, 0.5235], [0.0820, 0.1102])\n",
    "  im = torch.from_numpy(im)\n",
    "  #im = norm(im)\n",
    "  # convert to PIL for easier transforms\n",
    "  im_c1 = transforms.ToPILImage()(im[0]).resize((512,512))\n",
    "  im_c2 = transforms.ToPILImage()(im[1]).resize((512,512))\n",
    "  label = transforms.ToPILImage()(label.squeeze())\n",
    "\n",
    "  im_c1s = [F.crop(im_c1, 0, 0, 256, 256), F.crop(im_c1, 0, 256, 256, 256),\n",
    "            F.crop(im_c1, 256, 0, 256, 256), F.crop(im_c1, 256, 256, 256, 256)]\n",
    "  im_c2s = [F.crop(im_c2, 0, 0, 256, 256), F.crop(im_c2, 0, 256, 256, 256),\n",
    "            F.crop(im_c2, 256, 0, 256, 256), F.crop(im_c2, 256, 256, 256, 256)]\n",
    "  labels = [F.crop(label, 0, 0, 256, 256), F.crop(label, 0, 256, 256, 256),\n",
    "            F.crop(label, 256, 0, 256, 256), F.crop(label, 256, 256, 256, 256)]\n",
    "\n",
    "\n",
    "  ims = [torch.stack((transforms.ToTensor()(x).squeeze(),\n",
    "                    transforms.ToTensor()(y).squeeze()))\n",
    "                    for (x,y) in zip(im_c1s, im_c2s)]\n",
    "  ims = torch.stack([norm(im) for im in ims])\n",
    "  labels = [transforms.ToTensor()(label).squeeze() for label in labels]\n",
    "  labels = torch.stack(labels)\n",
    "  return ims[0], labels\n",
    "\n",
    "\n",
    "xp, yp = processTestIm(flood_data[1])\n",
    "#xp, yp = next(iter(test_loader))\n",
    "print(xp.shape)\n",
    "print(xp[1])\n",
    "Image.fromarray(xp[1][0].cpu().numpy() * 255).convert(\"L\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i6FvxodYeucT"
   },
   "outputs": [],
   "source": [
    "Image.fromarray(yp[3].cpu().numpy() * 255).convert(\"L\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zkE4vlgfiZxt"
   },
   "outputs": [],
   "source": [
    "print(flood_data[1][1].shape)\n",
    "Image.fromarray(flood_data[1][1][0] * 255).convert(\"L\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3NOBWKXmjdUq"
   },
   "outputs": [],
   "source": [
    "print(flood_data[1][1].shape)\n",
    "#im2 = transforms.ToTensor()(transforms.ToPILImage()(flood_data[1][1].squeeze()))\n",
    "im2 = torch.from_numpy(flood_data[1][1].squeeze())\n",
    "print(im2.cpu().numpy().shape)\n",
    "print(im2.cpu().numpy())\n",
    "print(flood_data[1][1].shape)\n",
    "print(flood_data[1][1])\n",
    "print(im2.cpu().numpy().dtype)\n",
    "print(flood_data[1][1].dtype)\n",
    "print(im2.cpu().numpy().shape)\n",
    "print(flood_data[1][1][0].shape)\n",
    "\n",
    "print(im2.cpu().numpy().round() == flood_data[1][1][0].round())\n",
    "print(np.sum((im2.cpu().numpy()[0].round() != flood_data[1][1][0].round())))\n",
    "Image.fromarray(im2.cpu().numpy() * 255).convert(\"L\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eerZvjqdlH6H"
   },
   "outputs": [],
   "source": [
    "next(iter(test_loader))[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S91aGycyYg37"
   },
   "outputs": [],
   "source": [
    "transforms.ToPILImage()(net(xp.cuda())[\"out\"][0].cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Xv6OvAP0Vntv"
   },
   "outputs": [],
   "source": [
    "im = Image.fromarray(np.uint8(train_data[0][0][0] * 255) , 'L')\n",
    "print(\"did stuff\")\n",
    "im.convert(\"L\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yufEdwAGctIB"
   },
   "outputs": [],
   "source": [
    "im = Image.fromarray(np.uint8(train_data[0][1][0] * 255) , 'L')\n",
    "print(\"did stuff\")\n",
    "im.convert(\"L\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dXSepXm9czPn"
   },
   "outputs": [],
   "source": [
    "test_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jCYc5gGYFA1x"
   },
   "outputs": [],
   "source": [
    "l.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ak9L0gyTE4yL"
   },
   "outputs": [],
   "source": [
    "i, l = valid_dataset[0]\n",
    "print(valid_file)\n",
    "im = Image.fromarray(np.uint8(l * 255) , 'L')\n",
    "im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DXx8kxjrFFHu"
   },
   "outputs": [],
   "source": [
    "#im = Image.fromarray(np.uint8(i[1][1] * 255) , 'L')\n",
    "print(i.numpy()[0].shape)\n",
    "im = Image.fromarray(i[0][0].cpu().numpy(), 'L')\n",
    "im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pmOh87HkJoEs"
   },
   "outputs": [],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cG85hdLDGnlx"
   },
   "outputs": [],
   "source": [
    "a = train_data[50][0][1]\n",
    "im = Image.fromarray((a * 255), \"L\")\n",
    "im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0HeeVGLgHVxb"
   },
   "outputs": [],
   "source": [
    "def download_flood_water_data_from_list(l):\n",
    "  i= 0\n",
    "  tot_nan = 0\n",
    "  tot_good = 0\n",
    "  flood_data = []\n",
    "  for (im_fname, mask_fname) in l:\n",
    "    arr_x = getArrFlood(os.path.join(\"/content/files4/S1\", im_fname))\n",
    "    print(os.path.join(\"/content/files4/QC_v2\", mask_fname))\n",
    "    arr_y = np.uint8(getArrFlood(os.path.join(\"/content/files4/QC_v2\", mask_fname)))\n",
    "    tot_nan += np.sum(arr_x != arr_x)\n",
    "    tot_good += np.sum(arr_x == arr_x)\n",
    "    if np.sum((arr_x != arr_x)) == 0:\n",
    "      ignore = np.uint8((arr_y == -1))\n",
    "      ignore = np.uint8(((np.uint8(ignore) * -1) * 256) + 1)\n",
    "      arr_y *= ignore\n",
    "      arr_x = np.clip(arr_x, -50, 1)\n",
    "      arr_x = (arr_x + 50) / 51\n",
    "      i += 1\n",
    "      flood_data.append((arr_x,arr_y))\n",
    "      print(i)\n",
    "    else:\n",
    "      print(\"skipping nan\")\n",
    "  print(tot_nan, tot_good)\n",
    "  return flood_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sFBNHx7IHoHQ"
   },
   "outputs": [],
   "source": [
    "arr_x = getArrFlood(os.path.join(\"/content/files4/S1\", \"India_179238_S1.tif\"))\n",
    "arr_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MQeqVczpH3vp"
   },
   "outputs": [],
   "source": [
    "arr_x = np.clip(arr_x, -50, 1)\n",
    "arr_x = (arr_x + 50) / 51\n",
    "print(arr_x)\n",
    "Image.fromarray(arr_x[0] * 255, \"L\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMf48pVkyLxuYqUrzgjC1Nw",
   "collapsed_sections": [],
   "include_colab_link": true,
   "machine_shape": "hm",
   "name": "Main Training Stuff.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0a5bf508b6b44bee8ce55182e0af6fec": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f93cc6f609e94593a6b7133ae868285e",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8a35991cccc84d0494384ac2c018727c",
      "value": 0
     }
    },
    "1c740a2079f04eb1b1c3586cf060087a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "25fb338b9ebb4053ac0218c253389a46": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "44ca7d253a0c46b3b704fe67a70c52eb": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_84eab0bbbc3d46e89df8e66cc3134be4",
      "max": 13,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ca76bbb74d4d45bc8a7ac4e1b5466e1b",
      "value": 11
     }
    },
    "51b4002a832f4754b087443f75d3c97f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ccd281b6c8104e4fa01533165fbb2ea0",
      "placeholder": "",
      "style": "IPY_MODEL_b9ec39f9a47248928f102018e2e0f116",
      "value": "  0% 0/2 [00:00&lt;?, ?it/s]"
     }
    },
    "52308f87ad3d46a885815de01d2a8402": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_fa7fbb20e21748568096c1aa226bf09d",
       "IPY_MODEL_65bfba0c282c4de2a8c7c738431f617f"
      ],
      "layout": "IPY_MODEL_1c740a2079f04eb1b1c3586cf060087a"
     }
    },
    "65bfba0c282c4de2a8c7c738431f617f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a22b328f55be4871929c1bf872887814",
      "placeholder": "",
      "style": "IPY_MODEL_67a9b7f67a274e1ca75dc8ea9c72e3b1",
      "value": "100% 130/130 [00:09&lt;00:00, 14.10it/s]"
     }
    },
    "67a9b7f67a274e1ca75dc8ea9c72e3b1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "785c07b1622a42648b66c6ce1ddf593f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "82300de7ef9c4460886669b056253500": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "84eab0bbbc3d46e89df8e66cc3134be4": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8a35991cccc84d0494384ac2c018727c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "8c714337e16c446281218656cb330d37": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_44ca7d253a0c46b3b704fe67a70c52eb",
       "IPY_MODEL_cca70317fa824574aa562d981391c46f"
      ],
      "layout": "IPY_MODEL_82300de7ef9c4460886669b056253500"
     }
    },
    "a22b328f55be4871929c1bf872887814": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b9ec39f9a47248928f102018e2e0f116": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bb6710d665f64746a816abac2cb6ad1a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c071047b9b5b420dbb5233397841a7b5": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ca76bbb74d4d45bc8a7ac4e1b5466e1b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "cca70317fa824574aa562d981391c46f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c071047b9b5b420dbb5233397841a7b5",
      "placeholder": "",
      "style": "IPY_MODEL_e5e4e39f80ff4ff4b1e2e723d71e64fa",
      "value": " 85% 11/13 [00:19&lt;00:03,  1.79s/it]"
     }
    },
    "ccd281b6c8104e4fa01533165fbb2ea0": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e5e4e39f80ff4ff4b1e2e723d71e64fa": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ed787105fcaa4c3c812a76c4c603d5f5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0a5bf508b6b44bee8ce55182e0af6fec",
       "IPY_MODEL_51b4002a832f4754b087443f75d3c97f"
      ],
      "layout": "IPY_MODEL_25fb338b9ebb4053ac0218c253389a46"
     }
    },
    "f93cc6f609e94593a6b7133ae868285e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fa7fbb20e21748568096c1aa226bf09d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_785c07b1622a42648b66c6ce1ddf593f",
      "max": 130,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_bb6710d665f64746a816abac2cb6ad1a",
      "value": 130
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
